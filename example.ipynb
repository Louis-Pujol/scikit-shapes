{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skshapes.morphing import ElasticMetric, RigidMotion, ElasticMetric2\n",
    "from skshapes.loss import OptimalTransportLoss, LandmarkLoss, NearestNeighborsLoss\n",
    "from skshapes.data import read\n",
    "from skshapes.tasks import DistanceMatrix, Registration, Registration2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning mesh005.ply to mesh047.ply...\n",
      "Aligning mesh001.ply to mesh047.ply...\n",
      "Aligning mesh042.ply to mesh047.ply...\n",
      "Aligning mesh027.ply to mesh047.ply...\n",
      "Aligning mesh003.ply to mesh047.ply...\n",
      "Aligning mesh023.ply to mesh047.ply...\n",
      "Aligning mesh026.ply to mesh047.ply...\n",
      "Aligning mesh022.ply to mesh047.ply...\n",
      "Aligning mesh028.ply to mesh047.ply...\n",
      "Aligning mesh033.ply to mesh047.ply...\n",
      "Aligning mesh021.ply to mesh047.ply...\n",
      "Aligning mesh044.ply to mesh047.ply...\n",
      "Aligning mesh004.ply to mesh047.ply...\n",
      "Aligning mesh024.ply to mesh047.ply...\n",
      "Aligning mesh070.ply to mesh047.ply...\n",
      "Aligning mesh029.ply to mesh047.ply...\n",
      "Aligning mesh034.ply to mesh047.ply...\n",
      "Aligning mesh011.ply to mesh047.ply...\n",
      "Aligning mesh048.ply to mesh047.ply...\n",
      "Aligning mesh012.ply to mesh047.ply...\n",
      "Aligning mesh068.ply to mesh047.ply...\n",
      "Aligning mesh052.ply to mesh047.ply...\n",
      "Aligning mesh000.ply to mesh047.ply...\n",
      "Aligning mesh065.ply to mesh047.ply...\n",
      "Aligning mesh018.ply to mesh047.ply...\n",
      "Aligning mesh032.ply to mesh047.ply...\n",
      "Aligning mesh046.ply to mesh047.ply...\n",
      "Aligning mesh038.ply to mesh047.ply...\n",
      "Aligning mesh017.ply to mesh047.ply...\n",
      "Aligning mesh025.ply to mesh047.ply...\n",
      "Aligning mesh040.ply to mesh047.ply...\n",
      "Aligning mesh036.ply to mesh047.ply...\n",
      "Aligning mesh016.ply to mesh047.ply...\n",
      "Aligning mesh010.ply to mesh047.ply...\n",
      "Aligning mesh064.ply to mesh047.ply...\n",
      "Aligning mesh057.ply to mesh047.ply...\n",
      "Aligning mesh041.ply to mesh047.ply...\n",
      "Aligning mesh058.ply to mesh047.ply...\n",
      "Aligning mesh030.ply to mesh047.ply...\n",
      "Aligning mesh069.ply to mesh047.ply...\n",
      "Aligning mesh056.ply to mesh047.ply...\n",
      "Aligning mesh009.ply to mesh047.ply...\n",
      "Aligning mesh054.ply to mesh047.ply...\n",
      "Aligning mesh060.ply to mesh047.ply...\n",
      "Aligning mesh053.ply to mesh047.ply...\n",
      "Aligning mesh071.ply to mesh047.ply...\n",
      "Aligning mesh002.ply to mesh047.ply...\n",
      "Aligning mesh063.ply to mesh047.ply...\n",
      "Aligning mesh019.ply to mesh047.ply...\n",
      "Aligning mesh045.ply to mesh047.ply...\n",
      "Aligning mesh043.ply to mesh047.ply...\n",
      "Aligning mesh020.ply to mesh047.ply...\n",
      "Aligning mesh037.ply to mesh047.ply...\n",
      "Aligning mesh067.ply to mesh047.ply...\n",
      "Aligning mesh050.ply to mesh047.ply...\n",
      "Aligning mesh007.ply to mesh047.ply...\n",
      "Aligning mesh061.ply to mesh047.ply...\n",
      "Aligning mesh049.ply to mesh047.ply...\n",
      "Aligning mesh066.ply to mesh047.ply...\n",
      "Aligning mesh013.ply to mesh047.ply...\n",
      "Aligning mesh035.ply to mesh047.ply...\n",
      "Aligning mesh015.ply to mesh047.ply...\n",
      "Aligning mesh062.ply to mesh047.ply...\n",
      "Aligning mesh014.ply to mesh047.ply...\n",
      "Aligning mesh059.ply to mesh047.ply...\n",
      "Aligning mesh039.ply to mesh047.ply...\n",
      "Aligning mesh006.ply to mesh047.ply...\n",
      "Aligning mesh031.ply to mesh047.ply...\n",
      "Aligning mesh055.ply to mesh047.ply...\n",
      "Aligning mesh008.ply to mesh047.ply...\n"
     ]
    }
   ],
   "source": [
    "##Â Rigid alignment (with landmarks)\n",
    "\n",
    "from skshapes.data import read\n",
    "from skshapes.tasks import Registration\n",
    "from skshapes.morphing import RigidMotion\n",
    "from skshapes.loss import LandmarkLoss\n",
    "from skshapes.optimization import LBFGS\n",
    "from skshapes.data import read\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "targetfolder = \"data/SCAPE_low_resolution_aligned\"\n",
    "datafolder = \"data/SCAPE_low_resolution\"\n",
    "\n",
    "files = os.listdir(datafolder)\n",
    "reference = read(datafolder + \"/\" + files[0])\n",
    "rest = [read(datafolder + \"/\" + file) for file in files[1:]]\n",
    "\n",
    "N = reference.points.shape[0]\n",
    "reference.landmarks = torch.arange(N, dtype=torch.int64)\n",
    "reference.to_pyvista().save(targetfolder + \"/\" + files[0])\n",
    "\n",
    "for i, mesh in enumerate(rest):\n",
    "    print(\"Aligning \" + files[i + 1] + \" to \" + files[0] + \"...\")\n",
    "    mesh.landmarks = torch.arange(N, dtype=torch.int64)\n",
    "\n",
    "    r = Registration(\n",
    "        model=RigidMotion(),\n",
    "        loss=LandmarkLoss(p=2),\n",
    "        optimizer=LBFGS(),\n",
    "        verbose=0,\n",
    "        n_iter=2,\n",
    "        device=\"cpu\",\n",
    "    )\n",
    "\n",
    "    morphed = r.fit_transform(source=mesh, target=reference)\n",
    "    morphed.to_pyvista().save(targetfolder + \"/\" + files[i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "Loss value at iteration 0 : 0.7949122190475464\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "Loss value at iteration 1 : 0.2929014563560486\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "Loss value at iteration 2 : 0.20722895860671997\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "Loss value at iteration 3 : 0.11527351289987564\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "Loss value at iteration 4 : 0.09861794114112854\n"
     ]
    }
   ],
   "source": [
    "##### ICP\n",
    "\n",
    "rotation = 1\n",
    "\n",
    "from skshapes.data import read, PolyData\n",
    "from skshapes.loss import NearestNeighborsLoss\n",
    "from skshapes.morphing import RigidMotion\n",
    "from skshapes.tasks import Registration\n",
    "from skshapes.optimization import LBFGS\n",
    "\n",
    "import torch\n",
    "\n",
    "# Load a mesh and apply a rotation\n",
    "mesh = read(\"data/SCAPE_low_resolution/mesh000.ply\")\n",
    "mesh.to_pyvista().save(\"source.vtk\")\n",
    "\n",
    "rotation = 5\n",
    "r = RigidMotion()\n",
    "parameter = torch.Tensor([[rotation, rotation, rotation], [0, 0, 0]])\n",
    "newmesh = r.morph(shape=mesh, parameter=parameter).morphed_shape\n",
    "newmesh.to_pyvista().save(\"target.vtk\")\n",
    "\n",
    "\n",
    "source = read(\"source.vtk\")\n",
    "target = read(\"target.vtk\")\n",
    "\n",
    "source.landmarks = torch.arange(source.points.shape[0], dtype=torch.int64)\n",
    "target.landmarks = torch.arange(target.points.shape[0], dtype=torch.int64)\n",
    "\n",
    "r = Registration(\n",
    "    model=RigidMotion(),\n",
    "    loss=NearestNeighborsLoss(),\n",
    "    optimizer=LBFGS(),\n",
    "    verbose=1,\n",
    "    n_iter=5,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "morphed = r.fit_transform(source=source, target=target)\n",
    "morphed.to_pyvista().save(\"output.vtk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value at iteration 0 : 5.045347213745117\n",
      "Loss value at iteration 1 : 0.05011105164885521\n",
      "Loss value at iteration 2 : 0.05011105164885521\n",
      "Loss value at iteration 3 : 0.05011105164885521\n",
      "Loss value at iteration 4 : 0.05011105164885521\n",
      "0.27788662910461426\n"
     ]
    }
   ],
   "source": [
    "# Elastic registration (with landmarks)\n",
    "\n",
    "from skshapes.data import read\n",
    "from skshapes.loss import LandmarkLoss\n",
    "from skshapes.morphing import ElasticMetric\n",
    "from skshapes.tasks import Registration\n",
    "from skshapes.optimization import LBFGS\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "datafolder = \"data/SCAPE_low_resolution_aligned\"\n",
    "\n",
    "source = read(datafolder + \"/\" + \"mesh001.ply\")\n",
    "target = read(datafolder + \"/\" + \"mesh041.ply\")\n",
    "\n",
    "source.landmarks = torch.arange(source.points.shape[0], dtype=torch.int64)\n",
    "target.landmarks = torch.arange(target.points.shape[0], dtype=torch.int64)\n",
    "\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "r = Registration(\n",
    "    model=ElasticMetric(n_steps=10),\n",
    "    loss=LandmarkLoss(),\n",
    "    optimizer=LBFGS(),\n",
    "    verbose=1,\n",
    "    n_iter=5,\n",
    "    regularization=100,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "newshape = r.fit_transform(source=source, target=target)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Shape' from 'skshapes.data' (/home/GitHub/scikit-shapes/skshapes/data/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/GitHub/scikit-shapes/example.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskshapes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     LandmarkSetter,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     Pipeline,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     Decimation,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     AffineTransformation,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskshapes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m read\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/scikit-shapes/skshapes/preprocessing/__init__.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset, Shape\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlandmarks_setter\u001b[39;00m \u001b[39mimport\u001b[39;00m LandmarkSetter\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdecimation\u001b[39;00m \u001b[39mimport\u001b[39;00m Decimation\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Shape' from 'skshapes.data' (/home/GitHub/scikit-shapes/skshapes/data/__init__.py)"
     ]
    }
   ],
   "source": [
    "from skshapes.preprocessing import (\n",
    "    LandmarkSetter,\n",
    "    Pipeline,\n",
    "    Decimation,\n",
    "    AffineTransformation,\n",
    ")\n",
    "from skshapes.data import read\n",
    "import os\n",
    "\n",
    "# Read the shapes\n",
    "datafolder = \"/home/GitHub/scikit-shapes-draft/data/SCAPE/decimated/\"\n",
    "shapes = [read(datafolder + \"/\" + f\"aligned_mesh{i:03d}.ply\") for i in range(4)]\n",
    "\n",
    "# Create a pipeline of preprocessing steps\n",
    "preprocessing = Pipeline(\n",
    "    steps=[\n",
    "        LandmarkSetter(landmarks=[[0, 1], [2, 3], [4, 5], [6, 70]], by_indices=True),\n",
    "        Decimation(target_reduction=0.95),\n",
    "        AffineTransformation(matrix=[[2, 0, 0], [0, 2, 0], [0, 0, 2]]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply the preprocessing pipeline to the shapes and get the dataset\n",
    "dataset = preprocessing.fit_transform(shapes=shapes)\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    print(\"Size of shape {} : {}\".format(i, dataset[i].points.shape))\n",
    "    print(\"Landmarks of shape {} : {}\".format(i, dataset.landmarks[i]), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def barycentric_coordinates(mesh, point):\n",
    "    # Compute the vectors from the point to the vertices\n",
    "    vertices = mesh.points\n",
    "    vectors = vertices - point\n",
    "    norms = torch.norm(vectors, dim=1)\n",
    "\n",
    "    tol = 1e-5  # TODO tol can be computed from the mesh resolution ?\n",
    "\n",
    "    # Test if a vector is zero (that means the point is a vertex of the mesh)\n",
    "    if torch.sum(vectors.abs().sum(dim=1) < tol):\n",
    "        indice = torch.where(\n",
    "            torch.all(torch.eq(vectors, torch.zeros_like(vectors)), dim=1)\n",
    "        )[0]\n",
    "        vertex_indice = int(indice[0])\n",
    "        print(\n",
    "            \"The point is a vertex of the mesh, at the following indice: {}\".format(\n",
    "                vertex_indice\n",
    "            )\n",
    "        )\n",
    "        return (torch.tensor(1.0), torch.tensor([vertex_indice]))\n",
    "\n",
    "    else:\n",
    "        # Normalize the vectors\n",
    "        vectors /= norms.reshape(-1, 1)\n",
    "\n",
    "        A = mesh.edges[0]\n",
    "        B = mesh.edges[1]\n",
    "\n",
    "        cos_angles = (vectors[A] * vectors[B]).sum(dim=1)\n",
    "        # If cos(angle) = -1 <=> angle = pi, the point is on an edge\n",
    "\n",
    "        if torch.sum((cos_angles - (-1)).abs() < tol):\n",
    "            indice = torch.where((cos_angles - (-1)).abs() < tol)[0]\n",
    "            edge_indice = int(indice[0])\n",
    "            print(\n",
    "                \"The point is on an edge of the mesh, at the following indice: {}\".format(\n",
    "                    edge_indice\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Coordinates\n",
    "            a, b = mesh.edges[:, edge_indice]\n",
    "            alpha = norms[b] / torch.norm(vertices[a] - vertices[b])\n",
    "            beta = norms[a] / torch.norm(vertices[a] - vertices[b])\n",
    "            assert torch.abs(alpha + beta - 1) < tol\n",
    "            assert (\n",
    "                (alpha * vertices[a] + beta * vertices[b]) - point\n",
    "            ).abs().sum() < tol\n",
    "            return (torch.tensor([alpha, beta]), torch.tensor([a, b]))\n",
    "\n",
    "        else:\n",
    "            A = mesh.triangles[0]\n",
    "            B = mesh.triangles[1]\n",
    "            C = mesh.triangles[2]\n",
    "\n",
    "            angles_1 = torch.acos((vectors[A] * vectors[B]).sum(dim=1))\n",
    "            angles_2 = torch.acos((vectors[B] * vectors[C]).sum(dim=1))\n",
    "            angles_3 = torch.acos((vectors[C] * vectors[A]).sum(dim=1))\n",
    "\n",
    "            sum_angles = angles_1 + angles_2 + angles_3\n",
    "            # If sum_angles is close to 2pi, the point is inside the triangle, or its projection is inside the triangle\n",
    "\n",
    "            if torch.sum((sum_angles - (2 * torch.pi)).abs() < tol):\n",
    "                indices = torch.where((sum_angles - (2 * torch.pi)).abs() < tol)[0]\n",
    "                # If several indices, we must find the one for which the point is inside irself the triangle, and not only its projection\n",
    "                for i in indices:\n",
    "                    a, b, c = mesh.triangles[:, i]\n",
    "                    normals = mesh.triangle_normals[i]\n",
    "\n",
    "                    if (\n",
    "                        torch.abs(vectors[a] @ normals.T)\n",
    "                        + torch.abs(vectors[b] @ normals.T)\n",
    "                        + torch.abs(vectors[c] @ normals.T)\n",
    "                        < tol\n",
    "                    ):\n",
    "                        indice_triangle = i\n",
    "\n",
    "                print(\n",
    "                    \"The point is inside a triangle of the mesh, at the following indice: {}\".format(\n",
    "                        indice_triangle\n",
    "                    )\n",
    "                )\n",
    "                # Coordinates\n",
    "                a, b, c = mesh.triangles[:, indice_triangle]\n",
    "                mat = torch.cat((vertices[a], vertices[b], vertices[c])).reshape(3, 3).T\n",
    "                alpha, beta, gamma = torch.inverse(mat) @ point\n",
    "                assert torch.abs(alpha + beta + gamma - 1) < tol\n",
    "                assert (\n",
    "                    (alpha * vertices[a] + beta * vertices[b] + gamma * vertices[c])\n",
    "                    - point\n",
    "                ).abs().sum() < tol\n",
    "                return (torch.tensor([alpha, beta, gamma]), torch.tensor([a, b, c]))\n",
    "\n",
    "            else:\n",
    "                print(\"The point is outside the mesh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The point is a vertex of the mesh, at the following indice: 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor([42]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skshapes.data import read\n",
    "\n",
    "mesh = read(\"data/SCAPE_low_resolution/mesh000.ply\")\n",
    "\n",
    "vertices = mesh.points\n",
    "e0, e1 = mesh.edges[:, 45]\n",
    "point_edge = (mesh.points[e0] + 4 * mesh.points[e1]) / 5\n",
    "a, b, c = mesh.triangles[:, 100]\n",
    "point_triangle = (mesh.points[a] + 4 * mesh.points[b] + 2 * mesh.points[c]) / 7\n",
    "point_vertice = mesh.points[42]\n",
    "\n",
    "point = point_vertice\n",
    "\n",
    "barycentric_coordinates(mesh, point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "from skshapes._typing import *\n",
    "\n",
    "\n",
    "class test(NamedTuple):\n",
    "    a: int = 0\n",
    "    b: int = 2\n",
    "\n",
    "\n",
    "t = test()\n",
    "t.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.load(\"landmarks.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices : tensor([[73, 94, 92, 73, 75, 94, 62, 73],\n",
      "        [ 0,  0,  0,  1,  1,  1,  2,  3]])\n",
      "Values : tensor([0.2522, 0.3066, 0.4412, 0.0768, 0.6896, 0.2336, 1.0000, 1.0000],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "landmark0 = a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m A \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([[\u001b[39m1.0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], [\u001b[39m4.1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m6.1\u001b[39m], [\u001b[39m0\u001b[39m, \u001b[39m8.2\u001b[39m, \u001b[39m0\u001b[39m]])\n\u001b[1;32m      4\u001b[0m \u001b[39mtype\u001b[39m(A)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.Tensor([[1.0, 0, 0], [4.1, 0, 6.1], [0, 8.2, 0]])\n",
    "type(A)\n",
    "B = A.to_sparse_coo()\n",
    "\n",
    "B.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import skshapes\n",
    "\n",
    "from skshapes.loss import L2Loss\n",
    "from skshapes.data import read\n",
    "from skshapes.morphing import ElasticMetric, RigidMotion\n",
    "from skshapes.tasks import Registration\n",
    "from skshapes.optimization import LBFGS\n",
    "import vedo\n",
    "\n",
    "vedo.settings.default_backend = \"vtk\"\n",
    "from vedo.applications import Browser\n",
    "\n",
    "# Load the shapes\n",
    "source = read(\"data/SCAPE_low_resolution/mesh001.ply\")\n",
    "target = read(\"data/SCAPE_low_resolution/mesh041.ply\")\n",
    "\n",
    "\n",
    "def foo(model, loss, optimizer, regularization):\n",
    "    r = Registration(\n",
    "        model=model,\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        n_iter=5,\n",
    "        regularization=regularization,\n",
    "        device=\"cpu\",\n",
    "    )\n",
    "\n",
    "    newshape = r.fit_transform(source=source, target=target)\n",
    "\n",
    "    print(r.parameter.device)\n",
    "    print(source.device)\n",
    "\n",
    "    a = model.morph(shape=source, parameter=r.parameter, return_path=True)\n",
    "\n",
    "    meshes = a.path\n",
    "    meshes.append(target)\n",
    "\n",
    "    return meshes\n",
    "\n",
    "    # plt = Browser([vedo.Mesh(m.to_pyvista()) for m in meshes], resetcam=0, axes=0)  # a vedo.Plotter\n",
    "    # plt.show().close()\n",
    "\n",
    "\n",
    "r = Registration(\n",
    "    model=RigidMotion(),\n",
    "    loss=L2Loss(),\n",
    "    optimizer=LBFGS(),\n",
    "    n_iter=2,\n",
    ")\n",
    "\n",
    "print(source.device)\n",
    "print(target.device)\n",
    "\n",
    "source = r.fit_transform(source=source, target=target)\n",
    "source = source.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "model = ElasticMetric(n_steps=5)\n",
    "loss = L2Loss()\n",
    "optimizer = LBFGS()\n",
    "\n",
    "meshes = foo(model, loss, optimizer, regularization=1000)\n",
    "\n",
    "vedo.settings.default_backend = \"vtk\"\n",
    "Browser([vedo.Mesh(m.to_pyvista()) for m in meshes], resetcam=0, axes=0).show().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skshapes.loss import OptimalTransportLoss\n",
    "\n",
    "loss = OptimalTransportLoss(loss=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from skshapes.data import read\n",
    "import pyvista\n",
    "from skshapes.morphing import ElasticMetric, RigidMotion\n",
    "from skshapes.loss import NearestNeighborsLoss, OptimalTransportLoss, LandmarkLoss\n",
    "from skshapes.optimization import LBFGS\n",
    "\n",
    "import vedo\n",
    "from vedo.applications import Browser\n",
    "\n",
    "source = read(\"data/SCAPE_low_resolution/mesh001.ply\")\n",
    "target = read(\"data/SCAPE_low_resolution/mesh041.ply\")\n",
    "\n",
    "\n",
    "# ElasticMetric can only be used with polydata\n",
    "# RigidMotion can be used with all type of shapes\n",
    "\n",
    "\n",
    "model = RigidMotion()\n",
    "loss = NearestNeighborsLoss()\n",
    "optimizer = LBFGS(model.parameters(), lr=0.1)\n",
    "\n",
    "from skshapes.tasks import Registration\n",
    "\n",
    "\n",
    "def foo(model, loss, optimizer, regularization):\n",
    "    r = Registration(\n",
    "        model=model,\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        n_iter=5,\n",
    "        device=\"cpu\",\n",
    "        regularization=regularization,\n",
    "    )\n",
    "\n",
    "    print(loss, model)\n",
    "    newshape = r.fit_transform(source=source, target=target)\n",
    "\n",
    "    parameter = r.parameter.detach().cpu().clone()\n",
    "    n_frames = parameter.shape[0] + 1\n",
    "\n",
    "    meshes = [source.copy(device=\"cpu\") for _ in range(n_frames)]\n",
    "    for i in range(n_frames - 1):\n",
    "        meshes[i + 1].points = meshes[i].points + parameter[i]\n",
    "\n",
    "    meshes = [vedo.Mesh(mesh.to_pyvista()) for mesh in meshes] + [\n",
    "        vedo.Mesh(target.to_pyvista())\n",
    "    ]\n",
    "\n",
    "    plt = Browser(meshes, resetcam=0, axes=0)  # a vedo.Plotter\n",
    "    plt.show().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules and load a model\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         4.62%       2.538ms        67.49%      37.060ms      37.060ms       0.000us         0.00%     649.000us     649.000us             1  \n",
      "                                Optimizer.step#SGD.step        39.87%      21.896ms        49.25%      27.044ms      13.522ms       0.000us         0.00%     424.000us     212.000us             2  \n",
      "                                       aten::unique_dim         0.63%     346.000us         2.09%       1.150ms     383.333us     212.000us        20.27%     236.000us      78.667us             3  \n",
      "    autograd::engine::evaluate_function: IndexBackward0         0.17%      93.000us        22.80%      12.518ms       1.565ms       0.000us         0.00%     233.000us      29.125us             8  \n",
      "                                         IndexBackward0         1.29%     708.000us        22.63%      12.425ms       1.553ms       0.000us         0.00%     233.000us      29.125us             8  \n",
      "                                 aten::_index_put_impl_        17.00%       9.335ms        20.73%      11.381ms       1.423ms     132.000us        12.62%     217.000us      27.125us             8  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us     183.000us        17.50%     183.000us      61.000us             3  \n",
      "                                            aten::copy_         1.07%     589.000us         9.84%       5.402ms      66.691us     134.000us        12.81%     134.000us       1.654us            81  \n",
      "                                            aten::index         0.99%     546.000us         1.88%       1.032ms      49.143us     104.000us         9.94%     104.000us       4.952us            21  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      95.000us         9.08%      95.000us       2.065us            46  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 54.912ms\n",
      "Self CUDA time total: 1.046ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skshapes.data import read\n",
    "import pyvista\n",
    "from skshapes.morphing import ElasticMetric\n",
    "from skshapes.loss import L2Loss\n",
    "from skshapes.optimization import SGD\n",
    "from skshapes.tasks import Registration\n",
    "\n",
    "import vedo\n",
    "from vedo.applications import Browser\n",
    "\n",
    "source = read(\"data/SCAPE_low_resolution/mesh001.ply\")\n",
    "target = read(\"data/SCAPE_low_resolution/mesh041.ply\")\n",
    "\n",
    "\n",
    "def foo(model, loss, optimizer, regularization):\n",
    "    r = Registration(\n",
    "        model=model,\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        n_iter=2,\n",
    "        device=\"cuda\",\n",
    "        regularization=regularization,\n",
    "    )\n",
    "\n",
    "    newshape = r.fit_transform(source=source, target=target)\n",
    "\n",
    "\n",
    "model = ElasticMetric()\n",
    "loss = L2Loss()\n",
    "optimizer = SGD()\n",
    "\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True\n",
    ") as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        foo(model, loss, optimizer, regularization=10)\n",
    "\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista\n",
    "import numpy as np\n",
    "\n",
    "from skshapes.data import PolyData\n",
    "\n",
    "mesh = PolyData.from_pyvista(pyvista.Sphere())\n",
    "\n",
    "n_points = mesh.n_points\n",
    "n_triangles = mesh.n_triangles\n",
    "n_edges = mesh.n_edges\n",
    "\n",
    "n_landmarks = 10\n",
    "\n",
    "landmarks_type = np.random.choice([\"points\", \"edges\", \"triangles\"], n_landmarks)\n",
    "\n",
    "import torch\n",
    "\n",
    "# Create landmarks (coo matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be careful\n"
     ]
    }
   ],
   "source": [
    "import skshapes as sks\n",
    "import pyvista\n",
    "\n",
    "mesh = pyvista.Sphere()\n",
    "\n",
    "test0 = sks.PolyData.from_pyvista(mesh)\n",
    "test1 = sks.PolyData(\"data/SCAPE_low_resolution/mesh001.ply\")\n",
    "test2 = sks.PolyData(\"data/SCAPE_low_resolution/mesh001.ply\").decimate(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "print(test1.n_points)\n",
    "print(test2.n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyvista\n",
    "\n",
    "sphere = pyvista.Sphere()\n",
    "sphere.decimate(0.5).n_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True <CallableBool>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0],\n",
       "        [1, 2, 1],\n",
       "        [2, 3, 2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pyvista\n",
    "import skshapes as sks\n",
    "\n",
    "points = np.random.rand(100, 3)\n",
    "\n",
    "points = np.concatenate([points, np.zeros((1, 3))], axis=0)\n",
    "points.shape\n",
    "\n",
    "pc = pyvista.PolyData(points, faces=[3, 0, 1, 2, 3, 1, 2, 3, 3, 0, 1, 2])\n",
    "\n",
    "print(pc.is_all_triangles)\n",
    "test = sks.PolyData(pc)\n",
    "\n",
    "test.triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/GitHub/scikit-shapes/example.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mallclose(test\u001b[39m.\u001b[39mpoints\u001b[39m.\u001b[39mnumpy(), clean_mesh\u001b[39m.\u001b[39mpoints)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m test_mesh_cleaning()\n",
      "\u001b[1;32m/home/GitHub/scikit-shapes/example.ipynb Cell 24\u001b[0m in \u001b[0;36mtest_mesh_cleaning\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m test \u001b[39m=\u001b[39m sks\u001b[39m.\u001b[39mPolyData(mesh)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mallclose(test\u001b[39m.\u001b[39mpoints\u001b[39m.\u001b[39mnumpy(), clean_mesh\u001b[39m.\u001b[39mpoints)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyvista\n",
    "import skshapes as sks\n",
    "\n",
    "\n",
    "def test_mesh_cleaning():\n",
    "    # Example of a mesh with duplicated points\n",
    "    points = np.array(\n",
    "        [\n",
    "            [0, 0, 0],\n",
    "            [1, 0, 0],\n",
    "            [0, 1, 0],\n",
    "            [0, 0, 0],\n",
    "            [1, 0, 0],\n",
    "            [0, 0, 1],\n",
    "        ],\n",
    "        dtype=np.float64,\n",
    "    )\n",
    "\n",
    "    faces = np.array([3, 0, 1, 2, 3, 3, 4, 5])\n",
    "\n",
    "    mesh = pyvista.PolyData(points, faces=faces)\n",
    "    clean_mesh = mesh.clean()\n",
    "\n",
    "    test = sks.PolyData(mesh)\n",
    "\n",
    "    # Check that the mesh is cleaned when loaded by skshapes\n",
    "    assert not np.allclose(test.points.numpy(), mesh.points)\n",
    "    assert np.allclose(test.points.numpy(), clean_mesh.points)\n",
    "\n",
    "\n",
    "test_mesh_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [3, 3],\n",
       "        [2, 1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(out[2][triangles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0],\n",
       "        [1, 2, 1],\n",
       "        [2, 3, 2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.clean().triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_points = np.union1d(np.unique(test.triangles), np.unique(test.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_points = np.setdiff1d(np.arange(test.n_points), used_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "       21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
       "       38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
       "       55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88,\n",
       "       89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unused_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8820, 0.9923, 0.9347],\n",
       "        [0.9883, 0.9599, 0.1837],\n",
       "        [0.8019, 0.0709, 0.0756],\n",
       "        [0.4919, 0.0044, 0.1344]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value at iteration 0 : 2.4044886231422424e-05\n",
      "Loss value at iteration 1 : 2.4044886231422424e-05\n",
      "Loss value at iteration 2 : 2.4044886231422424e-05\n",
      "Loss value at iteration 0 : 2.6265159249305725e-05\n",
      "Loss value at iteration 1 : 2.6265159249305725e-05\n",
      "Loss value at iteration 2 : 2.6265159249305725e-05\n",
      "Loss value at iteration 0 : 2.4044886231422424e-05\n",
      "Loss value at iteration 1 : 2.4044886231422424e-05\n",
      "Loss value at iteration 2 : 2.4044886231422424e-05\n",
      "Loss value at iteration 0 : 2.6265159249305725e-05\n",
      "Loss value at iteration 1 : 2.6265159249305725e-05\n",
      "Loss value at iteration 2 : 2.6265159249305725e-05\n"
     ]
    }
   ],
   "source": [
    "import skshapes as sks\n",
    "import pyvista.examples\n",
    "\n",
    "\n",
    "def test_registration_device():\n",
    "    \"\"\"This test ensure the behavior of the registration task with respect to the devices of the source, target and the gpu argument.\n",
    "    Expected behavior:\n",
    "        - If the gpu argument is True, the optimization should occurs on the gpu\n",
    "        - If the gpu argument is False, the optimization should occurs on the gpu\n",
    "        - The device of the output of .transform() and of .parameter_ should be the same as the device of the source and the target\n",
    "        - If source.device != target.device, an error should be raised\n",
    "    \"\"\"\n",
    "\n",
    "    shape1 = sks.PolyData(pyvista.Sphere())\n",
    "    shape2 = sks.PolyData(pyvista.Sphere()).decimate(0.5)\n",
    "\n",
    "    model = sks.RigidMotion()\n",
    "    loss = sks.OptimalTransportLoss()\n",
    "    optimizer = sks.LBFGS()\n",
    "\n",
    "    for device in [\"cpu\", \"cuda\"]:\n",
    "        for gpu in [False, True]:\n",
    "            source = shape1.to(device)\n",
    "            target = shape2.to(device)\n",
    "\n",
    "            task = sks.Registration(\n",
    "                model=model,\n",
    "                loss=loss,\n",
    "                optimizer=optimizer,\n",
    "                n_iter=3,\n",
    "                gpu=gpu,\n",
    "                regularization=10,\n",
    "                verbose=1,\n",
    "            )\n",
    "\n",
    "            newshape = task.fit_transform(source=source, target=target)\n",
    "\n",
    "            # Check that the device on which the optimization is performed corresponds to the gpu argument\n",
    "            if gpu:\n",
    "                assert task.internal_parameter_device_type == \"cuda\"\n",
    "            else:\n",
    "                assert task.internal_parameter_device_type == \"cpu\"\n",
    "\n",
    "            # Check that the device of the output is the same as the input's shapes\n",
    "            assert task.parameter_.device.type == source.device.type\n",
    "            assert newshape.device.type == target.device.type\n",
    "\n",
    "    # Check that if source and target are on different devices, an error is raised\n",
    "    source = shape1.to(\"cpu\")\n",
    "    target = shape2.to(\"cuda\")\n",
    "    try:\n",
    "        task.fit(source=source, target=target)\n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        raise AssertionError(\"Should have raised an error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<skshapes.loss.optimal_transport.OptimalTransportLoss at 0x7f4fa0329d60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_losses = [\n",
    "    i\n",
    "    for i in sks.loss.__dict__.values()\n",
    "    if isinstance(i, type) and issubclass(i, sks.Loss)\n",
    "]\n",
    "a = list_of_losses[0]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = shape1.to(\"cpu\")\n",
    "target = shape2.to(\"cuda\")\n",
    "\n",
    "list_of_losses = [\n",
    "    i\n",
    "    for i in sks.loss.__dict__.values()\n",
    "    if isinstance(i, type) and issubclass(i, sks.Loss)\n",
    "]\n",
    "for loss in list_of_losses:\n",
    "    l = loss()\n",
    "    try:\n",
    "        l(source=source, target=target)\n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        raise AssertionError(\"Should have raised an error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skshapes as sks\n",
    "\n",
    "mesh = sks.PolyData(\"data/SCAPE_low_resolution/mesh001.ply\")\n",
    "mesh.save(\"test.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 250])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh.triangles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1680, 3)\n"
     ]
    }
   ],
   "source": [
    "import pyvista\n",
    "import numpy as np\n",
    "import vedo\n",
    "\n",
    "sphere = pyvista.Sphere()\n",
    "mesh = vedo.Mesh(sphere)\n",
    "\n",
    "print(np.array(mesh.faces()).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skshapes as sks\n",
    "import pyvista\n",
    "import torch\n",
    "\n",
    "mesh = sks.PolyData(pyvista.Sphere())\n",
    "\n",
    "# Add some features\n",
    "mesh.features[\"hessians\"] = torch.rand(mesh.n_points, 3, 3)\n",
    "mesh.features[\"normals\"] = torch.rand(mesh.n_points, 3)\n",
    "mesh.features.append(torch.rand(mesh.n_points))\n",
    "\n",
    "try:\n",
    "    mesh.features.append(torch.rand(mesh.n_points + 1))\n",
    "except:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\n",
    "        \"Should have raised an error, the size of the tensor is not correct\"\n",
    "    )\n",
    "\n",
    "# Check that the features are correctly copied\n",
    "copy = mesh.copy()\n",
    "assert torch.allclose(copy.features[\"hessians\"], mesh.features[\"hessians\"])\n",
    "copy.features[\"hessians\"] = torch.rand(\n",
    "    mesh.n_points, 3, 3\n",
    ")  # If the copy was not correct, this would also change the features of the original mesh\n",
    "assert not torch.allclose(copy.features[\"hessians\"], mesh.features[\"hessians\"])\n",
    "\n",
    "new_features = {\n",
    "    \"rotations\": torch.rand(mesh.n_points, 3, 3),\n",
    "    \"colors\": torch.rand(mesh.n_points, 3),\n",
    "}\n",
    "\n",
    "mesh.features = new_features  # Replace the features\n",
    "mesh.features.append(torch.rand(mesh.n_points, 2))  # Add a new feature\n",
    "assert list(mesh.features.keys()) == [\n",
    "    \"rotations\",\n",
    "    \"colors\",\n",
    "    \"feature_0\",\n",
    "]  # Check the name of the features\n",
    "\n",
    "# Check that trying to set the features with a wrong type raises an error\n",
    "try:\n",
    "    mesh.features = 4\n",
    "except:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"Should have raised an error, the features should be a dict\")\n",
    "\n",
    "# Check that trying to set the features with an invalid dict (here the size of the tensors is not correct) raises an error\n",
    "try:\n",
    "    mesh.features = {\n",
    "        \"colors\": torch.rand(mesh.n_points + 2, 3),\n",
    "        \"normals\": torch.rand(mesh.n_points, 3),\n",
    "    }\n",
    "except:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\n",
    "        \"Should have raised an error, the size of the colors tensor is not correct\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class Parent:\n",
    "    pass\n",
    "\n",
    "\n",
    "class Child1(Parent):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Child2(Parent):\n",
    "    pass\n",
    "\n",
    "\n",
    "Children = Union[Child1, Child2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class definitions\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class Parent:\n",
    "    pass\n",
    "\n",
    "\n",
    "class Child1(Parent):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Child2(Parent):\n",
    "    pass\n",
    "\n",
    "\n",
    "Children = Union[Child1, Child2]\n",
    "\n",
    "\n",
    "#  Check that the Children type is correctly recognized\n",
    "def is_children(x):\n",
    "    for t in Children.__args__:\n",
    "        if isinstance(x, t):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "assert is_children(Child1())\n",
    "assert is_children(Child2())\n",
    "assert not is_children(Parent())\n",
    "\n",
    "# with typing module\n",
    "from typing import Union, get_origin, get_args\n",
    "\n",
    "assert get_origin(Children) == Union\n",
    "assert get_args(Children) == (Child1, Child2)\n",
    "\n",
    "assert issubclass(Child1, get_args(Children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/GitHub/scikit-shapes/example.ipynb Cell 40\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mskshapes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msks\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/scikit-shapes/skshapes/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfeatures\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/GitHub/scikit-shapes/skshapes/applications/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlandmark_setter\u001b[39;00m \u001b[39mimport\u001b[39;00m LandmarkSetter\n",
      "File \u001b[0;32m~/GitHub/scikit-shapes/skshapes/applications/landmark_setter.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m typecheck, List, float_dtype, int_dtype\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m PolyData\n\u001b[1;32m      9\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mLandmarkSetter\u001b[39;00m(vedo\u001b[39m.\u001b[39mPlotter):\n\u001b[1;32m     10\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"A LandmarkSetter is a vedo application that allows the user to select landmarks on a set of meshes.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m        meshes (List[vedo.Mesh]): The meshes on which the landmarks are selected.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m        **kwargs: Keyword arguments passed to the vedo.Plotter constructor.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/scikit-shapes/skshapes/data/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpolydata\u001b[39;00m \u001b[39mimport\u001b[39;00m PolyData\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbaseshape\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseShape\n",
      "File \u001b[0;32m~/GitHub/scikit-shapes/skshapes/data/polydata.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m Features\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m Shape\n\u001b[0;32m---> 33\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mPolyData\u001b[39;00m(BaseShape, Shape):\n\u001b[1;32m     34\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"A polygonal data object. It is composed of points, edges and triangles.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39m    For all these cases, it is possible to provide landmarks as a sparse tensor and device as a string or a torch device (\"cpu\" by default)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[39m@typecheck\u001b[39m\n\u001b[1;32m     46\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     47\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m         features: Optional[Features] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     55\u001b[0m     ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases"
     ]
    }
   ],
   "source": [
    "import skshapes as sks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/GitHub/scikit-shapes/example.ipynb Cell 41\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskshapes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m PolyData\n",
      "File \u001b[0;32m~/GitHub/scikit-shapes/skshapes/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfeatures\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/GitHub/scikit-shapes/skshapes/applications/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlandmark_setter\u001b[39;00m \u001b[39mimport\u001b[39;00m LandmarkSetter\n",
      "File \u001b[0;32m~/GitHub/scikit-shapes/skshapes/applications/landmark_setter.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m typecheck, List, float_dtype, int_dtype\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m PolyData\n\u001b[1;32m      9\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mLandmarkSetter\u001b[39;00m(vedo\u001b[39m.\u001b[39mPlotter):\n\u001b[1;32m     10\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"A LandmarkSetter is a vedo application that allows the user to select landmarks on a set of meshes.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m        meshes (List[vedo.Mesh]): The meshes on which the landmarks are selected.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m        **kwargs: Keyword arguments passed to the vedo.Plotter constructor.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/scikit-shapes/skshapes/data/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpolydata\u001b[39;00m \u001b[39mimport\u001b[39;00m PolyData\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbaseshape\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseShape\n",
      "File \u001b[0;32m~/GitHub/scikit-shapes/skshapes/data/polydata.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m Features\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m Shape\n\u001b[0;32m---> 33\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mPolyData\u001b[39;00m(BaseShape, Shape):\n\u001b[1;32m     34\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"A polygonal data object. It is composed of points, edges and triangles.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39m    For all these cases, it is possible to provide landmarks as a sparse tensor and device as a string or a torch device (\"cpu\" by default)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[39m@typecheck\u001b[39m\n\u001b[1;32m     46\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     47\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m         features: Optional[Features] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     55\u001b[0m     ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases"
     ]
    }
   ],
   "source": [
    "from skshapes.data import PolyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rotations': tensor([[[0.1382, 0.6877, 0.0877],\n",
       "          [0.3598, 0.1917, 0.9832],\n",
       "          [0.5377, 0.2768, 0.2052]],\n",
       " \n",
       "         [[0.4335, 0.5695, 0.8686],\n",
       "          [0.6195, 0.7661, 0.6209],\n",
       "          [0.3672, 0.2665, 0.3426]],\n",
       " \n",
       "         [[0.0662, 0.7519, 0.9919],\n",
       "          [0.0575, 0.8456, 0.3819],\n",
       "          [0.3575, 0.9073, 0.9821]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.9383, 0.6264, 0.2610],\n",
       "          [0.5657, 0.7263, 0.9791],\n",
       "          [0.3420, 0.3991, 0.2845]],\n",
       " \n",
       "         [[0.8103, 0.4226, 0.0378],\n",
       "          [0.5031, 0.2878, 0.9026],\n",
       "          [0.4386, 0.5266, 0.2401]],\n",
       " \n",
       "         [[0.0521, 0.8461, 0.4244],\n",
       "          [0.3968, 0.3237, 0.3137],\n",
       "          [0.6647, 0.7788, 0.4711]]]),\n",
       " 'colors': tensor([[0.0365, 0.0883, 0.2438],\n",
       "         [0.7887, 0.7964, 0.7347],\n",
       "         [0.1982, 0.2530, 0.3973],\n",
       "         ...,\n",
       "         [0.8254, 0.6396, 0.4923],\n",
       "         [0.2697, 0.3118, 0.3065],\n",
       "         [0.6510, 0.7550, 0.9164]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'blabla': 2, 'bloblo': 3}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "\n",
    "class test_features:\n",
    "    def __init__(self):\n",
    "        self.features = dict()\n",
    "\n",
    "    @property\n",
    "    def features(self):\n",
    "        return self._features\n",
    "\n",
    "    @features.setter\n",
    "    def features(self, value):\n",
    "        self._features = value\n",
    "        print(len(self._features))\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key not in self.traits.keys():\n",
    "            raise KeyError\n",
    "        ...\n",
    "        return traits[key]\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if key not in self.traits.keys():\n",
    "            raise KeyError\n",
    "        ...\n",
    "        traits[key] = value\n",
    "\n",
    "\n",
    "A = test_features()\n",
    "\n",
    "A.features[\"blabla\"] = 2\n",
    "A.features[\"bloblo\"] = 3\n",
    "\n",
    "A.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_curvature': tensor([[0.4318, 0.7755, 0.0413],\n",
       "         [0.7111, 0.8350, 0.8027],\n",
       "         [0.4680, 0.7629, 0.4850],\n",
       "         [0.6768, 0.3552, 0.1954],\n",
       "         [0.2301, 0.4838, 0.3052],\n",
       "         [0.4231, 0.3271, 0.9802],\n",
       "         [0.2544, 0.4447, 0.3851],\n",
       "         [0.7243, 0.7245, 0.8828],\n",
       "         [0.9862, 0.9709, 0.7198],\n",
       "         [0.4281, 0.2324, 0.5898]]),\n",
       " 'hessians': tensor([[[0.2523, 0.3315, 0.1120],\n",
       "          [0.3755, 0.8269, 0.0241],\n",
       "          [0.8761, 0.2696, 0.1949]],\n",
       " \n",
       "         [[0.1413, 0.1270, 0.8461],\n",
       "          [0.3032, 0.1933, 0.1752],\n",
       "          [0.5553, 0.3616, 0.1193]],\n",
       " \n",
       "         [[0.7530, 0.2402, 0.0795],\n",
       "          [0.8641, 0.5588, 0.4665],\n",
       "          [0.9988, 0.5972, 0.5083]],\n",
       " \n",
       "         [[0.7232, 0.7705, 0.4921],\n",
       "          [0.7764, 0.6138, 0.0954],\n",
       "          [0.1511, 0.5782, 0.0902]],\n",
       " \n",
       "         [[0.0174, 0.5757, 0.5882],\n",
       "          [0.3967, 0.9871, 0.3516],\n",
       "          [0.5024, 0.2297, 0.3222]],\n",
       " \n",
       "         [[0.0084, 0.1179, 0.8675],\n",
       "          [0.5481, 0.4982, 0.6385],\n",
       "          [0.6171, 0.3015, 0.0696]],\n",
       " \n",
       "         [[0.2228, 0.3285, 0.5934],\n",
       "          [0.1898, 0.0023, 0.3442],\n",
       "          [0.9305, 0.2155, 0.6513]],\n",
       " \n",
       "         [[0.9165, 0.5916, 0.1531],\n",
       "          [0.4346, 0.1655, 0.1762],\n",
       "          [0.0098, 0.2804, 0.8017]],\n",
       " \n",
       "         [[0.0464, 0.0867, 0.5203],\n",
       "          [0.6030, 0.9795, 0.3503],\n",
       "          [0.1182, 0.3460, 0.4883]],\n",
       " \n",
       "         [[0.3387, 0.1408, 0.4807],\n",
       "          [0.9735, 0.8086, 0.6400],\n",
       "          [0.6912, 0.3328, 0.0623]]]),\n",
       " 'colors': tensor([[4.7316e-01, 5.3187e-01, 1.4675e-04],\n",
       "         [1.7324e-01, 8.4604e-01, 7.1649e-01],\n",
       "         [1.9058e-01, 6.2902e-01, 8.1775e-01],\n",
       "         [2.0992e-01, 4.2326e-02, 1.8094e-01],\n",
       "         [3.4420e-01, 6.1643e-01, 8.7907e-01],\n",
       "         [8.7196e-01, 8.6392e-01, 2.0993e-01],\n",
       "         [7.7261e-01, 6.6982e-01, 7.1346e-01],\n",
       "         [8.8589e-01, 7.9795e-01, 1.6579e-01],\n",
       "         [6.1201e-02, 6.9289e-01, 1.3202e-01],\n",
       "         [6.2603e-02, 9.2546e-01, 3.1784e-01]]),\n",
       " 'feature_0': tensor([0.2570, 0.9951, 0.2061, 0.9195, 0.2967, 0.2567, 0.0863, 0.6681, 0.5657,\n",
       "         0.9107])}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Features(dict):\n",
    "    \"\"\"This class is a dictionary that contains features associated to a set (e.g. a set of points, a set of triangles, etc.)\n",
    "    When a feature is added to the dictionary, it is checked that the number of elements of the feature is the same as the number of elements of the set and\n",
    "    it is passed to the device of the set.\n",
    "\n",
    "    There are two ways to add a feature to the dictionary:\n",
    "        - By using the __setitem__ method (e.g. A[\"feature\"] = feature)\n",
    "        - By using the append method (e.g. A.append(feature)) which will automatically name the feature \"feature_{i}\" where i is the minimum integer such that \"feature_{i}\" is not already in the dictionary\n",
    "\n",
    "    Args:\n",
    "        n (int): The number of elements of the set\n",
    "        device (torch.device): The device on which the features should be stored\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, device):\n",
    "        self.n = n\n",
    "        self.device = device\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return dict.__getitem__(self, key)\n",
    "\n",
    "    def _check_value(self, value):\n",
    "        assert isinstance(value, torch.Tensor)\n",
    "        assert (\n",
    "            value.shape[0] == self.n\n",
    "        ), f\"Last dimension of the tensor should be {self.n}\"\n",
    "\n",
    "        if value.device != self.device:\n",
    "            value = value.to(self.device)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        # assert that the\n",
    "        value = self._check_value(value)\n",
    "        dict.__setitem__(self, key, value)\n",
    "\n",
    "    def append(self, value):\n",
    "        value = self._check_value(value)\n",
    "        i = 0\n",
    "        while f\"feature_{i}\" in self.keys():\n",
    "            i += 1\n",
    "\n",
    "        dict.__setitem__(self, f\"feature_{i}\", value)\n",
    "\n",
    "\n",
    "n = 10\n",
    "\n",
    "features = Features(n=n, device=\"cpu\")\n",
    "\n",
    "features[\"mean_curvature\"] = torch.rand(n, 3)\n",
    "features[\"hessians\"] = torch.rand(n, 3, 3)\n",
    "features[\"colors\"] = torch.rand(n, 3)\n",
    "\n",
    "features.append(torch.rand(n))\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skshapes.loss.baseloss import SumLoss, ProductLoss\n",
    "\n",
    "import skshapes as sks\n",
    "import pyvista\n",
    "\n",
    "shape1 = sks.PolyData(pyvista.Sphere())\n",
    "shape2 = sks.PolyData(pyvista.Sphere()).decimate(0.5)\n",
    "\n",
    "l = ProductLoss()\n",
    "l(source=shape1, target=shape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"blabla\"].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05405951  0.          0.00293103]\n",
      " [-0.05287818  0.0112396  -0.997069  ]\n",
      " [ 0.05405951  0.         -0.00293103]\n",
      " ...\n",
      " [-0.04919475 -0.01045667 -0.02003887]\n",
      " [-0.0510256  -0.01084583 -0.01448369]\n",
      " [-0.05225823 -0.01110783 -0.00875869]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyvista_ndarray([[0., 0., 0.],\n",
       "                 [0., 0., 0.],\n",
       "                 [0., 0., 0.],\n",
       "                 ...,\n",
       "                 [0., 0., 0.],\n",
       "                 [0., 0., 0.],\n",
       "                 [0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh = pyvista.Sphere()\n",
    "\n",
    "clean_mesh = mesh.clean()\n",
    "\n",
    "print(clean_mesh.points - mesh.points)\n",
    "\n",
    "# lexicographic order of clean_mesh.points\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "clean_ordering = np.lexsort(\n",
    "    (clean_mesh.points[:, 2], clean_mesh.points[:, 1], clean_mesh.points[:, 0])\n",
    ")\n",
    "ordering = np.lexsort((mesh.points[:, 2], mesh.points[:, 1], mesh.points[:, 0]))\n",
    "\n",
    "clean_mesh.points[clean_ordering] - mesh.points[ordering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8820, 0.9923, 0.9347],\n",
       "        [0.9883, 0.9599, 0.1837],\n",
       "        [0.8019, 0.0709, 0.0756],\n",
       "        [0.4919, 0.0044, 0.1344]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8820, 0.9923, 0.9347],\n",
       "        [0.9883, 0.9599, 0.1837],\n",
       "        [0.8019, 0.0709, 0.0756],\n",
       "        [0.4919, 0.0044, 0.1344],\n",
       "        [0.8820, 0.9923, 0.9347],\n",
       "        [0.9883, 0.9599, 0.1837],\n",
       "        [0.8019, 0.0709, 0.0756],\n",
       "        [0.4919, 0.0044, 0.1344],\n",
       "        [0.7408, 0.7317, 0.6218],\n",
       "        [0.7064, 0.8309, 0.5818],\n",
       "        [0.8745, 0.8094, 0.6827],\n",
       "        [0.3330, 0.8633, 0.5180],\n",
       "        [0.7064, 0.0074, 0.7339],\n",
       "        [0.1681, 0.4848, 0.3365],\n",
       "        [0.7491, 0.0339, 0.0977],\n",
       "        [0.7483, 0.9572, 0.5311],\n",
       "        [0.2669, 0.8152, 0.5799],\n",
       "        [0.2364, 0.0813, 0.7774],\n",
       "        [0.9923, 0.5683, 0.6883],\n",
       "        [0.1734, 0.4447, 0.6303],\n",
       "        [0.3287, 0.5583, 0.7417],\n",
       "        [0.7039, 0.2750, 0.4415],\n",
       "        [0.7741, 0.9224, 0.1883],\n",
       "        [0.4523, 0.9112, 0.2507],\n",
       "        [0.7684, 0.1591, 0.7342],\n",
       "        [0.0216, 0.7546, 0.1045],\n",
       "        [0.8616, 0.5509, 0.9817],\n",
       "        [0.1958, 0.6058, 0.7404],\n",
       "        [0.1663, 0.8967, 0.6868],\n",
       "        [0.9032, 0.8304, 0.9776],\n",
       "        [0.1612, 0.7075, 0.3830],\n",
       "        [0.8948, 0.6933, 0.7145],\n",
       "        [0.6811, 0.9436, 0.5208],\n",
       "        [0.7449, 0.2171, 0.4481],\n",
       "        [0.7367, 0.4852, 0.2655],\n",
       "        [0.9812, 0.4599, 0.9452],\n",
       "        [0.4830, 0.0775, 0.7765],\n",
       "        [0.8118, 0.1339, 0.9536],\n",
       "        [0.4330, 0.4273, 0.0232],\n",
       "        [0.2625, 0.4461, 0.8554],\n",
       "        [0.1727, 0.7515, 0.3565],\n",
       "        [0.0205, 0.0583, 0.8586],\n",
       "        [0.6530, 0.4875, 0.3553],\n",
       "        [0.1803, 0.3177, 0.7211],\n",
       "        [0.2712, 0.1871, 0.6076],\n",
       "        [0.3479, 0.2874, 0.5916],\n",
       "        [0.2192, 0.1140, 0.8691],\n",
       "        [0.1855, 0.7389, 0.6077],\n",
       "        [0.2952, 0.3446, 0.4453],\n",
       "        [0.4324, 0.5232, 0.8968],\n",
       "        [0.6943, 0.2136, 0.4529],\n",
       "        [0.3586, 0.4227, 0.6185],\n",
       "        [0.3673, 0.4254, 0.2869],\n",
       "        [0.5392, 0.2531, 0.8105],\n",
       "        [0.2322, 0.4743, 0.6589],\n",
       "        [0.8700, 0.8569, 0.8754],\n",
       "        [0.8289, 0.0886, 0.7208],\n",
       "        [0.2934, 0.9875, 0.4419],\n",
       "        [0.1838, 0.1343, 0.1163],\n",
       "        [0.7609, 0.4382, 0.1639],\n",
       "        [0.2148, 0.0287, 0.2420],\n",
       "        [0.9848, 0.2360, 0.9380],\n",
       "        [0.9373, 0.7910, 0.0737],\n",
       "        [0.7626, 0.9975, 0.0915],\n",
       "        [0.4470, 0.6763, 0.8372],\n",
       "        [0.8668, 0.3413, 0.8943],\n",
       "        [0.1632, 0.7292, 0.6153],\n",
       "        [0.9082, 0.0364, 0.5042],\n",
       "        [0.1451, 0.2530, 0.8733],\n",
       "        [0.5296, 0.6734, 0.5319],\n",
       "        [0.3131, 0.3022, 0.0353],\n",
       "        [0.8742, 0.1292, 0.5383],\n",
       "        [0.4730, 0.3010, 0.5059],\n",
       "        [0.0973, 0.6152, 0.1992],\n",
       "        [0.7309, 0.5075, 0.1136],\n",
       "        [0.3909, 0.6613, 0.6864],\n",
       "        [0.9403, 0.4030, 0.7400],\n",
       "        [0.6180, 0.2991, 0.1389],\n",
       "        [0.1809, 0.6864, 0.9785],\n",
       "        [0.9497, 0.6249, 0.2520],\n",
       "        [0.1812, 0.3088, 0.5184],\n",
       "        [0.2620, 0.6964, 0.8916],\n",
       "        [0.6349, 0.3156, 0.4355],\n",
       "        [0.5268, 0.7642, 0.8583],\n",
       "        [0.1361, 0.5247, 0.8639],\n",
       "        [0.2109, 0.4577, 0.4363],\n",
       "        [0.1192, 0.8041, 0.1178],\n",
       "        [0.6832, 0.2377, 0.9189],\n",
       "        [0.3547, 0.4612, 0.5549],\n",
       "        [0.1965, 0.1532, 0.2282],\n",
       "        [0.8148, 0.1086, 0.8056],\n",
       "        [0.5848, 0.8963, 0.3698],\n",
       "        [0.5743, 0.4713, 0.6661],\n",
       "        [0.4851, 0.3992, 0.1488],\n",
       "        [0.9357, 0.1798, 0.7027],\n",
       "        [0.8250, 0.0307, 0.2429],\n",
       "        [0.7761, 0.5862, 0.9491],\n",
       "        [0.9598, 0.3042, 0.7306],\n",
       "        [0.6233, 0.9280, 0.9855],\n",
       "        [0.1492, 0.9190, 0.9807],\n",
       "        [0.5068, 0.0467, 0.1985],\n",
       "        [0.9829, 0.7325, 0.8265],\n",
       "        [0.9020, 0.5061, 0.8398],\n",
       "        [0.4661, 0.6729, 0.5555]], dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PolyData' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/GitHub/scikit-shapes/example.ipynb Cell 50\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#Y100sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m pv_mesh\u001b[39m.\u001b[39mpoint_data[\u001b[39m\"\u001b[39m\u001b[39mcurvature\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(pv_mesh\u001b[39m.\u001b[39mn_points, \u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#Y100sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m mesh \u001b[39m=\u001b[39m sks\u001b[39m.\u001b[39mPolyData(pv_mesh)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#Y100sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39mallclose(mesh\u001b[39m.\u001b[39;49mfeatures[\u001b[39m\"\u001b[39m\u001b[39mcurvature\u001b[39m\u001b[39m\"\u001b[39m], pv_mesh\u001b[39m.\u001b[39mpoint_data[\u001b[39m\"\u001b[39m\u001b[39mcurvature\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PolyData' object has no attribute 'features'"
     ]
    }
   ],
   "source": [
    "import skshapes as sks\n",
    "import vedo\n",
    "import pyvista\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pv_mesh = pyvista.Sphere()\n",
    "pv_mesh.point_data[\"curvature\"] = np.random.rand(pv_mesh.n_points, 3)\n",
    "\n",
    "\n",
    "sks_mesh = sks.PolyData(pv_mesh)\n",
    "\n",
    "assert torch.allclose(sks_mesh.point_data[\"curvature\"], pv_mesh.point_data[\"curvature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "mesh = mesh.to(\"cuda\")\n",
    "print(mesh.device)\n",
    "print(mesh.point_data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/GitHub/scikit-shapes/example.ipynb Cell 53\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m d\u001b[39m.\u001b[39mvalues()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "d.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curvature (842, 3)\n"
     ]
    }
   ],
   "source": [
    "for key, value in mesh_pv.point_data.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in mesh_vedo.pointdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyvista DataSetAttributes\n",
       "Association     : POINT\n",
       "Active Scalars  : my_array\n",
       "Active Vectors  : None\n",
       "Active Texture  : TCoords\n",
       "Active Normals  : Normals\n",
       "Contains arrays :\n",
       "    Normals                 float32    (8, 3)               NORMALS\n",
       "    TCoords                 float32    (8, 2)               TCOORDS\n",
       "    my_array                float64    (8,)                 SCALARS\n",
       "    my_other_array          int64      (8,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh = pyvista.Cube()\n",
    "# mesh.clear_data()\n",
    "mesh.point_data[\"my_array\"] = np.random.random(mesh.n_points)\n",
    "mesh.point_data[\"my_other_array\"] = np.arange(mesh.n_points)\n",
    "mesh.point_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
