{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skshapes.morphing import ElasticMetric, RigidMotion, ElasticMetric2\n",
    "from skshapes.loss import OptimalTransportLoss, LandmarkLoss, NearestNeighborsLoss\n",
    "from skshapes.data import read\n",
    "from skshapes.tasks import DistanceMatrix, Registration, Registration2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning mesh005.ply to mesh047.ply...\n",
      "Aligning mesh001.ply to mesh047.ply...\n",
      "Aligning mesh042.ply to mesh047.ply...\n",
      "Aligning mesh027.ply to mesh047.ply...\n",
      "Aligning mesh003.ply to mesh047.ply...\n",
      "Aligning mesh023.ply to mesh047.ply...\n",
      "Aligning mesh026.ply to mesh047.ply...\n",
      "Aligning mesh022.ply to mesh047.ply...\n",
      "Aligning mesh028.ply to mesh047.ply...\n",
      "Aligning mesh033.ply to mesh047.ply...\n",
      "Aligning mesh021.ply to mesh047.ply...\n",
      "Aligning mesh044.ply to mesh047.ply...\n",
      "Aligning mesh004.ply to mesh047.ply...\n",
      "Aligning mesh024.ply to mesh047.ply...\n",
      "Aligning mesh070.ply to mesh047.ply...\n",
      "Aligning mesh029.ply to mesh047.ply...\n",
      "Aligning mesh034.ply to mesh047.ply...\n",
      "Aligning mesh011.ply to mesh047.ply...\n",
      "Aligning mesh048.ply to mesh047.ply...\n",
      "Aligning mesh012.ply to mesh047.ply...\n",
      "Aligning mesh068.ply to mesh047.ply...\n",
      "Aligning mesh052.ply to mesh047.ply...\n",
      "Aligning mesh000.ply to mesh047.ply...\n",
      "Aligning mesh065.ply to mesh047.ply...\n",
      "Aligning mesh018.ply to mesh047.ply...\n",
      "Aligning mesh032.ply to mesh047.ply...\n",
      "Aligning mesh046.ply to mesh047.ply...\n",
      "Aligning mesh038.ply to mesh047.ply...\n",
      "Aligning mesh017.ply to mesh047.ply...\n",
      "Aligning mesh025.ply to mesh047.ply...\n",
      "Aligning mesh040.ply to mesh047.ply...\n",
      "Aligning mesh036.ply to mesh047.ply...\n",
      "Aligning mesh016.ply to mesh047.ply...\n",
      "Aligning mesh010.ply to mesh047.ply...\n",
      "Aligning mesh064.ply to mesh047.ply...\n",
      "Aligning mesh057.ply to mesh047.ply...\n",
      "Aligning mesh041.ply to mesh047.ply...\n",
      "Aligning mesh058.ply to mesh047.ply...\n",
      "Aligning mesh030.ply to mesh047.ply...\n",
      "Aligning mesh069.ply to mesh047.ply...\n",
      "Aligning mesh056.ply to mesh047.ply...\n",
      "Aligning mesh009.ply to mesh047.ply...\n",
      "Aligning mesh054.ply to mesh047.ply...\n",
      "Aligning mesh060.ply to mesh047.ply...\n",
      "Aligning mesh053.ply to mesh047.ply...\n",
      "Aligning mesh071.ply to mesh047.ply...\n",
      "Aligning mesh002.ply to mesh047.ply...\n",
      "Aligning mesh063.ply to mesh047.ply...\n",
      "Aligning mesh019.ply to mesh047.ply...\n",
      "Aligning mesh045.ply to mesh047.ply...\n",
      "Aligning mesh043.ply to mesh047.ply...\n",
      "Aligning mesh020.ply to mesh047.ply...\n",
      "Aligning mesh037.ply to mesh047.ply...\n",
      "Aligning mesh067.ply to mesh047.ply...\n",
      "Aligning mesh050.ply to mesh047.ply...\n",
      "Aligning mesh007.ply to mesh047.ply...\n",
      "Aligning mesh061.ply to mesh047.ply...\n",
      "Aligning mesh049.ply to mesh047.ply...\n",
      "Aligning mesh066.ply to mesh047.ply...\n",
      "Aligning mesh013.ply to mesh047.ply...\n",
      "Aligning mesh035.ply to mesh047.ply...\n",
      "Aligning mesh015.ply to mesh047.ply...\n",
      "Aligning mesh062.ply to mesh047.ply...\n",
      "Aligning mesh014.ply to mesh047.ply...\n",
      "Aligning mesh059.ply to mesh047.ply...\n",
      "Aligning mesh039.ply to mesh047.ply...\n",
      "Aligning mesh006.ply to mesh047.ply...\n",
      "Aligning mesh031.ply to mesh047.ply...\n",
      "Aligning mesh055.ply to mesh047.ply...\n",
      "Aligning mesh008.ply to mesh047.ply...\n"
     ]
    }
   ],
   "source": [
    "##Â Rigid alignment (with landmarks)\n",
    "\n",
    "from skshapes.data import read\n",
    "from skshapes.tasks import Registration\n",
    "from skshapes.morphing import RigidMotion\n",
    "from skshapes.loss import LandmarkLoss\n",
    "from skshapes.optimization import LBFGS\n",
    "from skshapes.data import read\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "targetfolder = \"data/SCAPE_low_resolution_aligned\"\n",
    "datafolder = \"data/SCAPE_low_resolution\"\n",
    "\n",
    "files = os.listdir(datafolder)\n",
    "reference = read(datafolder + \"/\" + files[0])\n",
    "rest = [read(datafolder + \"/\" + file) for file in files[1:]]\n",
    "\n",
    "N = reference.points.shape[0]\n",
    "reference.landmarks = torch.arange(N, dtype=torch.int64)\n",
    "reference.to_pyvista().save(targetfolder + \"/\" + files[0])\n",
    "\n",
    "for i, mesh in enumerate(rest):\n",
    "    print(\"Aligning \" + files[i + 1] + \" to \" + files[0] + \"...\")\n",
    "    mesh.landmarks = torch.arange(N, dtype=torch.int64)\n",
    "\n",
    "    r = Registration(\n",
    "        model=RigidMotion(),\n",
    "        loss=LandmarkLoss(p=2),\n",
    "        optimizer=LBFGS(),\n",
    "        verbose=0,\n",
    "        n_iter=2,\n",
    "        device=\"cpu\",\n",
    "    )\n",
    "\n",
    "    morphed = r.fit_transform(source=mesh, target=reference)\n",
    "    morphed.to_pyvista().save(targetfolder + \"/\" + files[i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "Loss value at iteration 0 : 0.7949122190475464\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "Loss value at iteration 1 : 0.2929014563560486\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "Loss value at iteration 2 : 0.20722895860671997\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "Loss value at iteration 3 : 0.11527351289987564\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "Loss value at iteration 4 : 0.09861794114112854\n"
     ]
    }
   ],
   "source": [
    "##### ICP\n",
    "\n",
    "rotation = 1\n",
    "\n",
    "from skshapes.data import read, PolyData\n",
    "from skshapes.loss import NearestNeighborsLoss\n",
    "from skshapes.morphing import RigidMotion\n",
    "from skshapes.tasks import Registration\n",
    "from skshapes.optimization import LBFGS\n",
    "\n",
    "import torch\n",
    "\n",
    "# Load a mesh and apply a rotation\n",
    "mesh = read(\"data/SCAPE_low_resolution/mesh000.ply\")\n",
    "mesh.to_pyvista().save(\"source.vtk\")\n",
    "\n",
    "rotation = 5\n",
    "r = RigidMotion()\n",
    "parameter = torch.Tensor([[rotation, rotation, rotation], [0, 0, 0]])\n",
    "newmesh = r.morph(shape=mesh, parameter=parameter).morphed_shape\n",
    "newmesh.to_pyvista().save(\"target.vtk\")\n",
    "\n",
    "\n",
    "source = read(\"source.vtk\")\n",
    "target = read(\"target.vtk\")\n",
    "\n",
    "source.landmarks = torch.arange(source.points.shape[0], dtype=torch.int64)\n",
    "target.landmarks = torch.arange(target.points.shape[0], dtype=torch.int64)\n",
    "\n",
    "r = Registration(\n",
    "    model=RigidMotion(),\n",
    "    loss=NearestNeighborsLoss(),\n",
    "    optimizer=LBFGS(),\n",
    "    verbose=1,\n",
    "    n_iter=5,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "morphed = r.fit_transform(source=source, target=target)\n",
    "morphed.to_pyvista().save(\"output.vtk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value at iteration 0 : 5.045347213745117\n",
      "Loss value at iteration 1 : 0.05011105164885521\n",
      "Loss value at iteration 2 : 0.05011105164885521\n",
      "Loss value at iteration 3 : 0.05011105164885521\n",
      "Loss value at iteration 4 : 0.05011105164885521\n",
      "0.27788662910461426\n"
     ]
    }
   ],
   "source": [
    "# Elastic registration (with landmarks)\n",
    "\n",
    "from skshapes.data import read\n",
    "from skshapes.loss import LandmarkLoss\n",
    "from skshapes.morphing import ElasticMetric\n",
    "from skshapes.tasks import Registration\n",
    "from skshapes.optimization import LBFGS\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "datafolder = \"data/SCAPE_low_resolution_aligned\"\n",
    "\n",
    "source = read(datafolder + \"/\" + \"mesh001.ply\")\n",
    "target = read(datafolder + \"/\" + \"mesh041.ply\")\n",
    "\n",
    "source.landmarks = torch.arange(source.points.shape[0], dtype=torch.int64)\n",
    "target.landmarks = torch.arange(target.points.shape[0], dtype=torch.int64)\n",
    "\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "r = Registration(\n",
    "    model=ElasticMetric(n_steps=10),\n",
    "    loss=LandmarkLoss(),\n",
    "    optimizer=LBFGS(),\n",
    "    verbose=1,\n",
    "    n_iter=5,\n",
    "    regularization=100,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "newshape = r.fit_transform(source=source, target=target)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Shape' from 'skshapes.data' (/home/GitHub/scikit-shapes/skshapes/data/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/GitHub/scikit-shapes/example.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskshapes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     LandmarkSetter,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     Pipeline,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     Decimation,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     AffineTransformation,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskshapes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m read\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bkeops_full_container~localhost/home/GitHub/scikit-shapes/example.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/scikit-shapes/skshapes/preprocessing/__init__.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset, Shape\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlandmarks_setter\u001b[39;00m \u001b[39mimport\u001b[39;00m LandmarkSetter\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdecimation\u001b[39;00m \u001b[39mimport\u001b[39;00m Decimation\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Shape' from 'skshapes.data' (/home/GitHub/scikit-shapes/skshapes/data/__init__.py)"
     ]
    }
   ],
   "source": [
    "from skshapes.preprocessing import (\n",
    "    LandmarkSetter,\n",
    "    Pipeline,\n",
    "    Decimation,\n",
    "    AffineTransformation,\n",
    ")\n",
    "from skshapes.data import read\n",
    "import os\n",
    "\n",
    "# Read the shapes\n",
    "datafolder = \"/home/GitHub/scikit-shapes-draft/data/SCAPE/decimated/\"\n",
    "shapes = [read(datafolder + \"/\" + f\"aligned_mesh{i:03d}.ply\") for i in range(4)]\n",
    "\n",
    "# Create a pipeline of preprocessing steps\n",
    "preprocessing = Pipeline(\n",
    "    steps=[\n",
    "        LandmarkSetter(landmarks=[[0, 1], [2, 3], [4, 5], [6, 70]], by_indices=True),\n",
    "        Decimation(target_reduction=0.95),\n",
    "        AffineTransformation(matrix=[[2, 0, 0], [0, 2, 0], [0, 0, 2]]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply the preprocessing pipeline to the shapes and get the dataset\n",
    "dataset = preprocessing.fit_transform(shapes=shapes)\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    print(\"Size of shape {} : {}\".format(i, dataset[i].points.shape))\n",
    "    print(\"Landmarks of shape {} : {}\".format(i, dataset.landmarks[i]), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def barycentric_coordinates(mesh, point):\n",
    "    # Compute the vectors from the point to the vertices\n",
    "    vertices = mesh.points\n",
    "    vectors = vertices - point\n",
    "    norms = torch.norm(vectors, dim=1)\n",
    "\n",
    "    tol = 1e-5  # TODO tol can be computed from the mesh resolution ?\n",
    "\n",
    "    # Test if a vector is zero (that means the point is a vertex of the mesh)\n",
    "    if torch.sum(vectors.abs().sum(dim=1) < tol):\n",
    "        indice = torch.where(\n",
    "            torch.all(torch.eq(vectors, torch.zeros_like(vectors)), dim=1)\n",
    "        )[0]\n",
    "        vertex_indice = int(indice[0])\n",
    "        print(\n",
    "            \"The point is a vertex of the mesh, at the following indice: {}\".format(\n",
    "                vertex_indice\n",
    "            )\n",
    "        )\n",
    "        return (torch.tensor(1.0), torch.tensor([vertex_indice]))\n",
    "\n",
    "    else:\n",
    "        # Normalize the vectors\n",
    "        vectors /= norms.reshape(-1, 1)\n",
    "\n",
    "        A = mesh.edges[0]\n",
    "        B = mesh.edges[1]\n",
    "\n",
    "        cos_angles = (vectors[A] * vectors[B]).sum(dim=1)\n",
    "        # If cos(angle) = -1 <=> angle = pi, the point is on an edge\n",
    "\n",
    "        if torch.sum((cos_angles - (-1)).abs() < tol):\n",
    "            indice = torch.where((cos_angles - (-1)).abs() < tol)[0]\n",
    "            edge_indice = int(indice[0])\n",
    "            print(\n",
    "                \"The point is on an edge of the mesh, at the following indice: {}\".format(\n",
    "                    edge_indice\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Coordinates\n",
    "            a, b = mesh.edges[:, edge_indice]\n",
    "            alpha = norms[b] / torch.norm(vertices[a] - vertices[b])\n",
    "            beta = norms[a] / torch.norm(vertices[a] - vertices[b])\n",
    "            assert torch.abs(alpha + beta - 1) < tol\n",
    "            assert (\n",
    "                (alpha * vertices[a] + beta * vertices[b]) - point\n",
    "            ).abs().sum() < tol\n",
    "            return (torch.tensor([alpha, beta]), torch.tensor([a, b]))\n",
    "\n",
    "        else:\n",
    "            A = mesh.triangles[0]\n",
    "            B = mesh.triangles[1]\n",
    "            C = mesh.triangles[2]\n",
    "\n",
    "            angles_1 = torch.acos((vectors[A] * vectors[B]).sum(dim=1))\n",
    "            angles_2 = torch.acos((vectors[B] * vectors[C]).sum(dim=1))\n",
    "            angles_3 = torch.acos((vectors[C] * vectors[A]).sum(dim=1))\n",
    "\n",
    "            sum_angles = angles_1 + angles_2 + angles_3\n",
    "            # If sum_angles is close to 2pi, the point is inside the triangle, or its projection is inside the triangle\n",
    "\n",
    "            if torch.sum((sum_angles - (2 * torch.pi)).abs() < tol):\n",
    "                indices = torch.where((sum_angles - (2 * torch.pi)).abs() < tol)[0]\n",
    "                # If several indices, we must find the one for which the point is inside irself the triangle, and not only its projection\n",
    "                for i in indices:\n",
    "                    a, b, c = mesh.triangles[:, i]\n",
    "                    normals = mesh.triangle_normals[i]\n",
    "\n",
    "                    if (\n",
    "                        torch.abs(vectors[a] @ normals.T)\n",
    "                        + torch.abs(vectors[b] @ normals.T)\n",
    "                        + torch.abs(vectors[c] @ normals.T)\n",
    "                        < tol\n",
    "                    ):\n",
    "                        indice_triangle = i\n",
    "\n",
    "                print(\n",
    "                    \"The point is inside a triangle of the mesh, at the following indice: {}\".format(\n",
    "                        indice_triangle\n",
    "                    )\n",
    "                )\n",
    "                # Coordinates\n",
    "                a, b, c = mesh.triangles[:, indice_triangle]\n",
    "                mat = torch.cat((vertices[a], vertices[b], vertices[c])).reshape(3, 3).T\n",
    "                alpha, beta, gamma = torch.inverse(mat) @ point\n",
    "                assert torch.abs(alpha + beta + gamma - 1) < tol\n",
    "                assert (\n",
    "                    (alpha * vertices[a] + beta * vertices[b] + gamma * vertices[c])\n",
    "                    - point\n",
    "                ).abs().sum() < tol\n",
    "                return (torch.tensor([alpha, beta, gamma]), torch.tensor([a, b, c]))\n",
    "\n",
    "            else:\n",
    "                print(\"The point is outside the mesh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The point is a vertex of the mesh, at the following indice: 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor([42]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skshapes.data import read\n",
    "\n",
    "mesh = read(\"data/SCAPE_low_resolution/mesh000.ply\")\n",
    "\n",
    "vertices = mesh.points\n",
    "e0, e1 = mesh.edges[:, 45]\n",
    "point_edge = (mesh.points[e0] + 4 * mesh.points[e1]) / 5\n",
    "a, b, c = mesh.triangles[:, 100]\n",
    "point_triangle = (mesh.points[a] + 4 * mesh.points[b] + 2 * mesh.points[c]) / 7\n",
    "point_vertice = mesh.points[42]\n",
    "\n",
    "point = point_vertice\n",
    "\n",
    "barycentric_coordinates(mesh, point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "from skshapes._typing import *\n",
    "\n",
    "\n",
    "class test(NamedTuple):\n",
    "    a: int = 0\n",
    "    b: int = 2\n",
    "\n",
    "\n",
    "t = test()\n",
    "t.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.load(\"landmarks.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices : tensor([[73, 94, 92, 73, 75, 94, 62, 73],\n",
      "        [ 0,  0,  0,  1,  1,  1,  2,  3]])\n",
      "Values : tensor([0.2522, 0.3066, 0.4412, 0.0768, 0.6896, 0.2336, 1.0000, 1.0000],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "landmark0 = a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m A \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([[\u001b[39m1.0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], [\u001b[39m4.1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m6.1\u001b[39m], [\u001b[39m0\u001b[39m, \u001b[39m8.2\u001b[39m, \u001b[39m0\u001b[39m]])\n\u001b[1;32m      4\u001b[0m \u001b[39mtype\u001b[39m(A)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.Tensor([[1.0, 0, 0], [4.1, 0, 6.1], [0, 8.2, 0]])\n",
    "type(A)\n",
    "B = A.to_sparse_coo()\n",
    "\n",
    "B.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import skshapes\n",
    "\n",
    "from skshapes.loss import L2Loss\n",
    "from skshapes.data import read\n",
    "from skshapes.morphing import ElasticMetric, RigidMotion\n",
    "from skshapes.tasks import Registration\n",
    "from skshapes.optimization import LBFGS\n",
    "import vedo\n",
    "\n",
    "vedo.settings.default_backend = \"vtk\"\n",
    "from vedo.applications import Browser\n",
    "\n",
    "# Load the shapes\n",
    "source = read(\"data/SCAPE_low_resolution/mesh001.ply\")\n",
    "target = read(\"data/SCAPE_low_resolution/mesh041.ply\")\n",
    "\n",
    "\n",
    "def foo(model, loss, optimizer, regularization):\n",
    "    r = Registration(\n",
    "        model=model,\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        n_iter=5,\n",
    "        regularization=regularization,\n",
    "        device=\"cpu\",\n",
    "    )\n",
    "\n",
    "    newshape = r.fit_transform(source=source, target=target)\n",
    "\n",
    "    print(r.parameter.device)\n",
    "    print(source.device)\n",
    "\n",
    "    a = model.morph(shape=source, parameter=r.parameter, return_path=True)\n",
    "\n",
    "    meshes = a.path\n",
    "    meshes.append(target)\n",
    "\n",
    "    return meshes\n",
    "\n",
    "    # plt = Browser([vedo.Mesh(m.to_pyvista()) for m in meshes], resetcam=0, axes=0)  # a vedo.Plotter\n",
    "    # plt.show().close()\n",
    "\n",
    "\n",
    "r = Registration(\n",
    "    model=RigidMotion(),\n",
    "    loss=L2Loss(),\n",
    "    optimizer=LBFGS(),\n",
    "    n_iter=2,\n",
    ")\n",
    "\n",
    "print(source.device)\n",
    "print(target.device)\n",
    "\n",
    "source = r.fit_transform(source=source, target=target)\n",
    "source = source.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "model = ElasticMetric(n_steps=5)\n",
    "loss = L2Loss()\n",
    "optimizer = LBFGS()\n",
    "\n",
    "meshes = foo(model, loss, optimizer, regularization=1000)\n",
    "\n",
    "vedo.settings.default_backend = \"vtk\"\n",
    "Browser([vedo.Mesh(m.to_pyvista()) for m in meshes], resetcam=0, axes=0).show().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skshapes.loss import OptimalTransportLoss\n",
    "\n",
    "loss = OptimalTransportLoss(loss=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from skshapes.data import read\n",
    "import pyvista\n",
    "from skshapes.morphing import ElasticMetric, RigidMotion\n",
    "from skshapes.loss import NearestNeighborsLoss, OptimalTransportLoss, LandmarkLoss\n",
    "from skshapes.optimization import LBFGS\n",
    "\n",
    "import vedo\n",
    "from vedo.applications import Browser\n",
    "\n",
    "source = read(\"data/SCAPE_low_resolution/mesh001.ply\")\n",
    "target = read(\"data/SCAPE_low_resolution/mesh041.ply\")\n",
    "\n",
    "\n",
    "# ElasticMetric can only be used with polydata\n",
    "# RigidMotion can be used with all type of shapes\n",
    "\n",
    "\n",
    "model = RigidMotion()\n",
    "loss = NearestNeighborsLoss()\n",
    "optimizer = LBFGS(model.parameters(), lr=0.1)\n",
    "\n",
    "from skshapes.tasks import Registration\n",
    "\n",
    "\n",
    "def foo(model, loss, optimizer, regularization):\n",
    "    r = Registration(\n",
    "        model=model,\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        n_iter=5,\n",
    "        device=\"cpu\",\n",
    "        regularization=regularization,\n",
    "    )\n",
    "\n",
    "    print(loss, model)\n",
    "    newshape = r.fit_transform(source=source, target=target)\n",
    "\n",
    "    parameter = r.parameter.detach().cpu().clone()\n",
    "    n_frames = parameter.shape[0] + 1\n",
    "\n",
    "    meshes = [source.copy(device=\"cpu\") for _ in range(n_frames)]\n",
    "    for i in range(n_frames - 1):\n",
    "        meshes[i + 1].points = meshes[i].points + parameter[i]\n",
    "\n",
    "    meshes = [vedo.Mesh(mesh.to_pyvista()) for mesh in meshes] + [\n",
    "        vedo.Mesh(target.to_pyvista())\n",
    "    ]\n",
    "\n",
    "    plt = Browser(meshes, resetcam=0, axes=0)  # a vedo.Plotter\n",
    "    plt.show().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules and load a model\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         4.62%       2.538ms        67.49%      37.060ms      37.060ms       0.000us         0.00%     649.000us     649.000us             1  \n",
      "                                Optimizer.step#SGD.step        39.87%      21.896ms        49.25%      27.044ms      13.522ms       0.000us         0.00%     424.000us     212.000us             2  \n",
      "                                       aten::unique_dim         0.63%     346.000us         2.09%       1.150ms     383.333us     212.000us        20.27%     236.000us      78.667us             3  \n",
      "    autograd::engine::evaluate_function: IndexBackward0         0.17%      93.000us        22.80%      12.518ms       1.565ms       0.000us         0.00%     233.000us      29.125us             8  \n",
      "                                         IndexBackward0         1.29%     708.000us        22.63%      12.425ms       1.553ms       0.000us         0.00%     233.000us      29.125us             8  \n",
      "                                 aten::_index_put_impl_        17.00%       9.335ms        20.73%      11.381ms       1.423ms     132.000us        12.62%     217.000us      27.125us             8  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us     183.000us        17.50%     183.000us      61.000us             3  \n",
      "                                            aten::copy_         1.07%     589.000us         9.84%       5.402ms      66.691us     134.000us        12.81%     134.000us       1.654us            81  \n",
      "                                            aten::index         0.99%     546.000us         1.88%       1.032ms      49.143us     104.000us         9.94%     104.000us       4.952us            21  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      95.000us         9.08%      95.000us       2.065us            46  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 54.912ms\n",
      "Self CUDA time total: 1.046ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skshapes.data import read\n",
    "import pyvista\n",
    "from skshapes.morphing import ElasticMetric\n",
    "from skshapes.loss import L2Loss\n",
    "from skshapes.optimization import SGD\n",
    "from skshapes.tasks import Registration\n",
    "\n",
    "import vedo\n",
    "from vedo.applications import Browser\n",
    "\n",
    "source = read(\"data/SCAPE_low_resolution/mesh001.ply\")\n",
    "target = read(\"data/SCAPE_low_resolution/mesh041.ply\")\n",
    "\n",
    "\n",
    "def foo(model, loss, optimizer, regularization):\n",
    "    r = Registration(\n",
    "        model=model,\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        n_iter=2,\n",
    "        device=\"cuda\",\n",
    "        regularization=regularization,\n",
    "    )\n",
    "\n",
    "    newshape = r.fit_transform(source=source, target=target)\n",
    "\n",
    "\n",
    "model = ElasticMetric()\n",
    "loss = L2Loss()\n",
    "optimizer = SGD()\n",
    "\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True\n",
    ") as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        foo(model, loss, optimizer, regularization=10)\n",
    "\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['edges', 'points', 'points', 'triangles', 'points', 'points',\n",
       "       'triangles', 'triangles', 'points', 'edges'], dtype='<U9')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyvista\n",
    "import numpy as np\n",
    "from pyvista.examples import load_airplane\n",
    "\n",
    "from skshapes.data import PolyData\n",
    "\n",
    "mesh = PolyData.from_pyvista(pyvista.Sphere())\n",
    "\n",
    "n_points = mesh.n_points\n",
    "n_triangles = mesh.n_triangles\n",
    "n_edges = mesh.n_edges\n",
    "\n",
    "n_landmarks = 10\n",
    "\n",
    "landmarks_type = np.random.choice([\"points\", \"edges\", \"triangles\"], n_landmarks)\n",
    "\n",
    "import torch\n",
    "\n",
    "# Create landmarks (coo matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit-shapes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8883c2b94226e7135f297eeda6bf7ecdfca88a7ef3be77921963dc18ba1f7c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
